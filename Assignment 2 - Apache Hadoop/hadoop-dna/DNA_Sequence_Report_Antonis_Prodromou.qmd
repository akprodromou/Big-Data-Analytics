---
title: "Technologies for Big Data Analytics"
subtitle: "Εργασία 2 - Hadoop and MapReduce - Υποερώτημα 2: DNA Tuple Counter"

author: "Antonis Prodromou"

date: today

format:
  pdf:
    toc: true
    number-sections: true
    colorlinks: true
    lang: el-GR

    mainfont: "Roboto"
    sansfont: "Arial"
    monofont: "Menlo"

    df-print: kable

    include-in-header:
      text: |
        % no polyglossia
        \usepackage{pdflscape}
    babel-lang: "none"
---

## Περιγραφή Λύσης - Υποερώτημα 2

### Σκοπός

Σε αυτή την εργασία, αναπτύσσουμε ένα πρόγραμμα MapReduce σε Java για την ανάλυση ακολουθιών DNA. Ο σκοπός είναι η καταμέτρηση της συχνότητας εμφάνισης n-tuples (υποακολουθιών) συγκεκριμένου μήκους μέσα σε ένα σύνολο δεδομένων DNA.

Συγκεκριμένα, το πρόγραμμα επεξεργάζεται τις γραμμές εισόδου και παράγει συνδυασμούς για:

* 2-tuples (διπλές ακολουθίες, π.χ. "AT")
* 3-tuples (τριπλές ακολουθίες, π.χ. "TGC")
* 4-tuples (τετραπλές ακολουθίες, π.χ. "AGTC")

Το πρόγραμμα είναι σχεδιασμένο να αγνοεί κενές γραμμές, ενώ η ολίσθηση του παραθύρου (sliding window) για την εξαγωγή των tuples γίνεται ανά χαρακτήρα, εξασφαλίζοντας ότι καταγράφονται όλες οι πιθανές αλληλουχίες εντός των δεδομένων.

Οι ακολουθίες DNA που καταγράφουμε ανήκουν στο κολοβακτηρίδιο Escherichia coli και τα δεδομένα εισόδου βρίσκονται στο αρχείο `ecoli.txt`.

---

### Περιβάλλον

Στο συγκεκριμένο Virtual Machine που θα τρέξουμε το πρόγραμμα έχουμε Pseudo-Distributed λειτουργία, στην οποία σύμφωνα με το [documentation](https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/SingleCluster.html):

- Κάθε daemon τρέχει ως ξεχωριστή διαδικασία σε παράλληλα JVMs.
- Τα αρχεία HDFS διατηρούνται σε 3 αντίτυπα όμως όλα βρίσκονται αποθηκευμένα στον ίδιο υπολογιστή (τοπικά), στο `hdfs://localhost:9000`.

---

### Κλάσεις

Για τον καθορισμό των κλάσεων, ακολουθούμε την αρχή της Μοναδικής Αρμοδιότητας, επομένως δημιουργούμε τρεις κλάσεις, τις `CountMapper`, `CountReducer` και `DNACounter` οι οποίες έχουν τις εξής αρμοδιότητες:

#### CountMapper

Η `CountMapper` κληρονομεί την κλάση Mapper, η οποία είναι υπεύθυνη για την επεξεργασία ακατέργαστων δεδομένων, μετατρέποντάς τα σε δομημένα (structured) με τη μορφή ζεύγους (κλειδιών - τιμών).

Αρχικά ορίζουμε τη μεταβλητή `one` χρησιμοποιώντας την κλάση `IntWritable` για την σειριακοποίηση του `1`. Η μέθοδος `map` ξεκινά με τον καθαρισμό της γραμμής εισόδου από περιττά κενά με τη χρήση της `trim()`. Αν η γραμμή είναι κενή, η επεξεργασία σταματά.

Στη συνέχεια, εφαρμόζει δύο nested loops για την παραγωγή των tuples:
1. Ο εξωτερικός βρόχος (`n`) καθορίζει το μήκος του tuple (από 2 έως 4).
2. Ο εσωτερικός βρόχος (`i`) διατρέχει τη συμβολοσειρά και εξάγει την υποακολουθία χρησιμοποιώντας τη μέθοδο `substring()`.

```java
for (int n = 2; n <= 4; n++) {
    for (int i = 0; i <= line.length() - n; i++) {
        String sub = line.substring(i, i + n);
        tuple.set(sub);
        context.write(tuple, one);
    }
}
```

Η έξοδος της map() περιέχει ζεύγη όπως ("AT", 1), ("ATG", 1), ("ATGC", 1).

---

#### CountReducer

Η `CountReducer` κληρονομεί την κλάση Reducer. Τα συνολικά αθροίσματα των τιμών για κάθε κλειδί (tuple) αποθηκεύονται σε ένα `IntWritable`. Χρησιμοποιούμε ένα for loop το οποίο παίρνει την κάθε τιμή (val) από το iterable (values), μετατρέπει τον IntWritable σε ακέραιο μέσω του get(), και τις αθροίζει. Στο τέλος σειριακοποιούμε και πάλι την τιμή με `set()` και γράφουμε το αποτέλεσμα στο HDFS.

---

#### DNACounter

Η κλάση `DNACounter` λειτουργεί ως ο Driver του προγράμματος και υλοποιεί το interface Tool χρησιμοποιώντας την κλάση Configured. Αυτή η προσέγγιση επιτρέπει την καλύτερη διαχείριση του configuration μέσω του ToolRunner.

Η μέθοδος `run()` ρυθμίζει τις παραμέτρους της εργασίας (Job):

- Ορίζει τις κλάσεις Mapper και Reducer.

- Καθορίζει τους τύπους δεδομένων εξόδου (`Text` και `IntWritable`).

- Ορίζει τα paths εισόδου και εξόδου που λαμβάνει από τα arguments.

- Στη main καλούμε την `ToolRunner.run()`, η οποία αναλαμβάνει την προετοιμασία του περιβάλλοντος και την εκτέλεση της εργασίας.

---

### Πώς εκτελούμε το πρόγραμμα

Καθώς η συγκεκριμένη εγκατάσταση του Hadoop είναι ρυθμισμένη με το HDFS ως προεπιλογή, προετοιμάζουμε τον φάκελο εισόδου:

```
# δημιουργία φακέλου εισόδου
hdfs dfs -mkdir -p /user/anton/dna_input
# μεταφορά του αρχείου εισόδου
hdfs dfs -put dna_sequences.txt /user/anton/dna_input/
```

Στη συνέχεια τρέχουμε το jar χρησιμοποιώντας το hadoop binary:

```
# εκτέλεση της MapReduce εργασίας
~/bdc/hadoop-3.2.1/bin/hadoop jar dna_counter.jar com.anton.dna.DNACounter /user/anton/dna_input /user/anton/dna_output
```

Τα αποτελέσματα αποθηκεύονται σε αρχείο με τίτλο part-r-00000.

---

### Αποτελέσματα

Τα αποτελέσματα παρουσιάζουν τη συχνότητα όλων των πιθανών συνδυασμών 2-mer, 3-mer και 4-mer και δίνονται στο επισυναπτόμενο αρχείο `output.txt`. Έχουν την παρακάτω μορφή:

```
AA	    333113
AAA	    105855
AAAA	33644
AAAC	24149
```