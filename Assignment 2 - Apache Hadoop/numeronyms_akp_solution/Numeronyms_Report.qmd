---
title: "Technologies for Big Data Analytics"
subtitle: "Εργασία 2 - Hadoop and MapReduce - Υποερώτημα 1: Numeronyms"

author: "Antonis Prodromou"

date: today

format:
  pdf:
    toc: true
    number-sections: true
    colorlinks: true
    lang: el-GR

    mainfont: "Roboto"
    sansfont: "Arial"
    monofont: "Menlo"

    df-print: kable

    include-in-header:
      text: |
        % no polyglossia
        \usepackage{pdflscape}
    babel-lang: "none"
---

## Περιγραφή Λύσης - Υποερώτημα 1

### Σκοπός

Στην εργασία αυτή χρησιμοποιούμε το Apache Hadoop για τη δημιουργία ενός προγράμματος MapReduce σε Java. Ο σκοπός του προγράμματος είναι να πάρει ως δεδομένα εισόδου ένα κείμενο και να μετρήσει τα numeronyms, που είναι τα αλφαριθμητικά που σχηματίζονται λαμβάνοντας τον πρώτο και τον τελευταίο χαρακτήρα της λέξης, βάζοντας ενδιάμεσα ως ακέραιο αριθμό το πλήθος των χαρακτήρων μεταξύ αυτών.

Το πρόγραμμα έχει συνταχθεί ώστε να αγνοεί:

* Τις λέξεις μικρότερες από 3 χαρακτήρες
* Τα σημεία στίξης
* Την διάκριση ανάμεσα σε κεφαλαία και μικρά γράμματα, είναι δηλαδή case-insensitive

Ως υπερπαράμετρο έχουμε το ελάχιστο πλήθος εμφανίσεων k ενός numeronym για το οποίο ενδιαφερόμαστε. Το αποτέλεσμα του προγράμματος είναι μια 
λίστα με numeronyms και το πλήθος εμφανίσεων του κάθε numeronym που είναι μεγαλύτερο ή ίσο της παραμέτρου k που δίνεται από το χρήστη. Για τη συγκεκριμένη
εργασία χρησιμοποιείται για την ανάλυση το βιβλίο «The Adventures of Sherlock Holmes» του Sir Arthur Conan Doyle, που διατίθεται από τη βιβλιοθήκη Gutenberg.

---

### Περιβάλλον

Στο συγκεκριμένο Virtual Machine που θα τρέξουμε το πρόγραμμα έχουμε Pseudo-Distributed λειτουργία, στην οποία σύμφωνα με το [documentation](https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/SingleCluster.html):

- Κάθε daemon τρέχει ως ξεχωριστή διαδικασία σε παράλληλα JVMs.
- Τα αρχεία HDFS διατηρούνται σε 3 αντίτυπα όμως όλα βρίσκονται αποθηκευμένα στον ίδιο υπολογιστή (τοπικά), στο `hdfs://localhost:9000`.

---

### Κλάσεις

Για τον καθορισμό των κλάσεων, ακολουθούμε την αρχή της Μοναδικής Αρμοδιότητας, επομένως δημιουργούμε τρεις κλάσεις, τις `NumeronymMapper`, `NumeronymDriver`  και `NumeronymReducer` οποίες έχουν τις εξής αρμοδιότητες:

#### NumeronymMapper

Η `NumeronymMapper` κληρονομεί την κλάση Mapper, η οποία είναι υπεύθυνη για την επεξεργασία ακατέργαστων δεδομένων, μετατρέποντάς τα σε δομημένα (structured) με τη μορφή ζεύγους (κλειδιών - τιμών), τα οποία μπορεί να διαχειριστεί η Hadoop.

Αρχικά ορίζουμε τη μεταβλητή `oneValue` χρησιμοποιώντας την κλάση `IntWritable` για την σειριακοποίηση (serialization) του `1` σε αναπαράσταση δυαδικής μορφής, μειώνοντας τον απαιτούμενο αποθηκευτικό χώρο και αυξάνοντας την ταχύτητα των υπολογισμών.

Η μέθοδος `map` ξεκινάει με την κανονικοποίηση (σε πεζά) των γραμμών εισόδου αφαιρώντας σημεία στίξης και ειδικά σύμβολα. Στη συνέχεια χρησιμοποιούμε την κλάση `StringTokenizer()` για να μετατρέψουμε κάθε γραμμή σε tokens, τα οποία εν προκειμένω διαχωρίζονται από whitespaces (κενά) και άρα - δεδομένης της κανονικοποίησης που προηγήθηκε - είναι λέξεις.

Στη συνέχεια, για κάθε token χρησιμοποιούμε την `charAt()` για να πάρουμε το πρώτο και το τελευταίο γράμμα (στα index 0 και n-1). Ο ενδιάμεσος αριθμός χαρακτήρων `word.length() - 2` μετατρέπεται επίσης σε String και γίνεται concatenate:

```
String num = word.charAt(0) + String.valueOf(word.length() - 2) + 
  word.charAt(word.length() - 1);
```

Η έξοδος της `map()` είναι της μορφής:

```
("j9n", 1)
("m4r", 1)
("h4p", 1)
("m4r", 1)
```

Δηλαδή τα κλειδιά επαναλαμβάνονται στις λέξεις που συναντώνται παραπάνω από μια φορά.

---

Ανάμεσα στο Map και πριν το Reduce, το Hadoop πραγματοποιεί μια ανακατάταξη (shuffle), κατά την οποία τα δεδομένα μεταφέρονται από Map κόμβους σε επιμέρους κόμβους Reduce. Κατά τη διάρκεια αυτής της διαδικασίας, τα κλειδιά γκρουπάρονται και παράλληλα ταξινομούνται («sorted», εν προκειμένω με αλφαβητική σειρά). Οπότε ο reducer λαμβάνει κάθε κλειδί μόνο μια φορά, μαζί με έναν iterator με όλες του τις τιμές, π.χ. ("m4r", [1, 1, 1, 1]).

---

#### NumeronymReducer

Η `NumeronymReducer` κληρονομεί την κλάση Reducer. Τα συνολικά αθροίσματα των τιμών για κάθε κλειδί αποθηκεύονται κι εδώ σε ένα `IntWritable`. Ως προς τη διαδικασία, χρησιμοποιούμε ένα for loop το οποίο παίρνει την κάθε τιμή (val) από το iterable (values), μετατρέπει τον `IntWritable` σε ακέραιο μέσω του get(), και τις αθροίζει. Στο τέλος σειριακοποιούμε και πάλι την τιμή με `set()` και γράφουμε το αποτέλεσμα στο αρχείο, στο HDFS.

---

#### NumeronymDriver

Ο NumeronymDriver παίρνει ως μεταβλητές την τοποθεσία του κειμένου προς επεξεργασία (`<input path>`), την τοποθεσία αποθήκευσης (`<output path>`) και το k που ορίζει τις ελάχιστες εμφανίσεις των numeronyms στο κείμενο. Χρησιμοποιούμε ένα αντικείμενο `Configuration()` για να αποθηκεύσουμε όλες τις ρυθμίσεις και παραμέτρους της συγκεκριμένης εργασίας που θα τρέξουμε. Για την συγκεκριμένη εφαρμογή θέτω ως παράμετρο το ελάχιστο πλήθος εμφανίσεων, με τη γραμμή :

```
conf.setInt("numeronym.min.count", k);
```

Στη συνέχεια περνάμε το configuration σε ένα αντικείμενο της κλάσης `Job()`, ώστε να κληρονομήσει αυτές τις ιδιότητες. Ακολούθως ορίζουμε τα Mapper, Reducer, τον τύπο δεδομένων εξόδου (`setOutputKeyClass`) και τις διευθύνσεις εισόδου και εξόδου.

---

### Πώς εκτελούμε το πρόγραμμα

Καθώς η συγκεκριμένη εγκατάσταση του Hadoop είναι ρυθμισμένη με το Hadoop Distributed File System (HDFS) ως προεπιλογή, πρέπει αντίστοιχα να προετοιμάσουμε και τον φάκελο εισόδου στον υπολογιστή που θα τρέξουμε το πρόγραμμα (να είναι HDFS path δηλαδή). Το directory εξόδου φτιάχνεται από το hadoop αυτόματα.

```
# create input directory
bashhdfs dfs -mkdir -p /user/anton/input
# μεταφέρω το αρχείο εισόδου στο directory
hdfs dfs -put SherlockHolmes.txt /user/anton/input/
```

Στη συνέχεια τρέχουμε το jar για τη συγκεκριμένη εργασία χρησιμοποιώντας το hadoop binary:

```
# run MapReduce job to include all occurences
~/bdc/hadoop-3.2.1/bin/hadoop jar numeronym.jar com.anton.numeronym.NumeronymDriver /user/anton/input /user/anton/sh_numeronym_output 1
```

Ενώ για να φιλτράρουμε για k = 10 έχουμε:

```
# run MapReduce job to include all occurences
~/bdc/hadoop-3.2.1/bin/hadoop jar numeronym.jar com.anton.numeronym.NumeronymDriver /user/anton/input /user/anton/sh_numeronym_output 10
```

Τα αποτελέσματα αποθηκεύονται σε αρχείο με τίτλο `part-r-00000`

---

### Αποτελέσματα

Τα αποτελέσματα που παίρνουμε είναι αυτής της μορφής:

```
...
a2s	488
a2t	51
a2v	1
a2w	7
...
```

Με συνολικά 3830 αποτελέσματα numeronyms με μήκος λέξης >= 3 χαρακτήρων.

Με sort έχουμε τα παρακάτω με τη μεγαλύτερη συχνότητα:

```
t1e	80074
a1d	38444
t2t	12701
h1s	11633
w1s	11409
```

Τρέχοντας το πρόγραμμα με k=10 ως ελάχιστο πλήθος εμφανίσεων ενός numeronym παίρνουμε 2407 αποτελέσματα, δηλαδή το 62.8% των αρχικών.
